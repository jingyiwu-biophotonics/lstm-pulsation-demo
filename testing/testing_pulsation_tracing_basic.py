#!/usr/bin/env python
# coding: utf-8

# # LSTM Pulsation Tracing
# 
# This notebook demonstrates a minimal, end-to-end workflow for applying a trained LSTM to trace cardiac pulsations in optical waveforms (e.g., NIRS, PPG, DCS). It also covers pulse segmentation and ensemble averaging to produce representative beats for downstream analyses (timing metrics, morphology features, and quality control). For questions, please contact Jingyi Wu (jingyiwu@andrew.cmu.edu).
# ## General Pipeline
# 1. Load a 1×N waveform and apply basic preprocessing (resample → scale).
# 2. Run windowed inference with the trained LSTM to obtain a cleaned/denoised trace.
# 3. Detect beats (peaks or valleys), segment pulses, and compute averaged waveforms.
# 4. Visualizations include time trace overlays, segment comparisons, spectrograms, and signal quality index (SNR) time traces.

def main():
    # ## Import packages

    # In[1]:


    # Uncomment the next line to install your repo dependencies.
    # !pip install -r requirements_test.txt


    # In[2]:


    import os
    import math
    import random

    import numpy as np
    import h5py
    from scipy.io import loadmat

    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import Dataset, DataLoader

    import matplotlib.pyplot as plt
    # get_ipython().run_line_magic('matplotlib', 'inline')
    import matplotlib.gridspec as gridspec
    import plotly.io as pio
    # pio.renderers.default = 'iframe' # this might create a folder named "iframe_figures" and save the interactive plots generated by this script
    pio.renderers.default = 'browser'
    # pio.renderers.default = 'vscode' # if user is using vscode

    plt.ion()
    def show_now(fig=None):
        """Non-blocking show for scripts."""
        if fig is not None:
            fig.canvas.draw_idle()
        plt.show(block=False)
        plt.pause(0.001)

    color5 = ['#eb5055', '#405FC1', '#ffaa1c', '#62a140', '#9E3AB7'] # Color for plots


    # ## 1. Load pre-trained LSTM model

    # In[3]:


    # Select device
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")

    # Candidate model files
    model_names = [
        'lstm_full_dataset.pt'
    ]

    model_folder = "testing/models/"

    # Pick model by index
    idx_model = 0
    model_name = model_names[idx_model]
    print(f"Model selected: {model_name}")

    # Initialize model architecture
    model = LSTMDetectionModel(n_hid=256, n_layers=1).to(device)

    # Load saved weights
    state_dict = torch.load(os.path.join(model_folder, model_name), map_location=device)
    model.load_state_dict(state_dict)

    # Move model to device (redundant but explicit)
    model = model.to(device)

    print("Model loaded successfully!")


    # ## 2. Loading and Preprocessing Test Data
    # 
    # In this section, we load an example experimental dataset to demonstrate the analysis pipeline.  
    # Additional datasets are available in the folders `experimental_data`, `synthetic_data`, or on KiltHub (see README).
    # 
    # Two example datasets are included:
    # - **`nirs_fiber_shaking.mat`** – Fiber-shaking case (as shown in the paper)  
    # - **`nirs_shaking.mat`** – Head-shaking case (as shown in the paper)  
    # 
    # You can switch between them by adjusting the dataset index in the code below.
    # 
    # **Notes:**
    # - To load your own data, make sure the dimensions are consistent:  
    #   - `data_pick` should be **1 × time**.  
    #   - A sampling frequency `fs_data` must be provided.  
    # - If your `.mat` file uses different field names (e.g., `signal`, `fs`), update the keys accordingly in the loading step.
    # 

    # In[4]:


    test_files = ['nirs_fiber_shaking.mat', # fiber shaking example in the paper
                'nirs_head_shaking.mat'] # head shaking example in the paper

    # Pick which dataset to test
    idx_file = 0
    test_file = test_files[idx_file]
    print("Test file: " + test_file + " is picked!")

    # Build full path and load dataset
    test_folder = 'testing/experimental_data/'
    test_path = test_folder + test_file
    dataset = loadmat(test_path)
    print(dataset.keys())


    # In[5]:


    # Extract raw signal (single channel, reshape to row vector)
    data_pick = dataset['signal'][0].reshape(-1, 1).T
    print(data_pick.shape)  # should be 1 × time

    # Extract sampling frequency from the dataset
    # Note: if it differs from 50 Hz (training data fs), it will be resampled later
    fs_data = dataset['fs'][0][0] * 1.0
    print(fs_data)

    # Figure title based on filename for plotting
    figure_title = f"{test_file.removesuffix('.mat')}"
    print(figure_title)


    # ### Preprocessing
    # Convert raw intensity to delta optical density (dOD) if necessary:
    # - Training data were PPG-like waveforms (systolic peak pointing upward).
    # - Thus, measured DC intensity signals from NIRS need conversion to dOD. For signals already resembling PPG, like pulsatile blood flow from DCS, this conversion is not necessary.
    # - But, our model will still trace the pulses without this conversion, and users are encouraged to experiment with it.

    # In[6]:


    time_trace_raw = -np.log(data_pick / np.nanmean(data_pick))

    # For handling nan in data
    # eps = 1e-12
    # time_trace_raw = -np.log(time_trace_raw_input / (np.nanmean(data_pick) + eps))


    # Preprocessing steps:
    # 
    # 1. Resample to 50 Hz (to match training data).
    # 2. Center signal around zero.
    # 3. Normalize so that pulsations roughly lie in [-1, 1].
    # 
    # Current implementation uses Hilbert transform and envelope detection to auto-scale the pulse amplitude, 
    # but it is not always perfect. Users may need to manually tune:
    # 
    #   `amplitude_scale` : controls vertical scaling
    #   
    #   `offset`          : shifts the center up or down
    # 
    # Practical tips:
    #    - After normalization, visually check the time trace for appropriate scaling.
    #    - An additional check is to look at segmented and averaged pulse waveforms 
    #      (plotted at the end of the script). If normalization is done correctly, both 
    #      raw and LSTM-processed averaged waveforms should have very similar amplitude and fall roughly within [-1, 1].
    #    - This step is critical: carefully adjusting scaling leads to much better results.

    # In[7]:


    fs_origin = fs_data
    fs_target = 50.0 # Training data were sampled at 50 Hz
    t_nirs, time_trace, signal_scale = preprocess_signal(time_trace_raw, fs_origin, fs_target, amplitude_scale=0.95, offset=0.1, plt_fig=False)


    # ## 3. Process signal with LSTM
    # 
    # For input signals of arbitrary length, we first segment them into fixed-length windows (the same size used during training).  
    # Each segment is processed independently by the trained LSTM model, and then recombined into a full-length time trace.  
    # Overlapping regions between segments are averaged for smooth reconstruction.
    # 
    # We also compare the raw vs. processed signals, estimate the signal quality index (SNR), and visualize spectrograms before and after processing.
    # 

    # In[8]:


    # Segmentation parameters
    # Window size must match training data length (1 min at 50 Hz → 3000 samples).
    # Overlap size can be adjusted: larger overlap = smoother stitching, more compute.
    window_size = 3000
    overlap_size = 2000

    # Segment the full trace into overlapping windows
    segments = segment_time_trace(time_trace, window_size, overlap_size)

    # Optional: visualize segmentation
    # plot_segments(time_trace, segments, window_size, overlap_size, 
    #               "Segmented Time Traces")

    # Run the trained LSTM model on each segment
    processed_segments = process_segments_with_lstm(model, segments, device)

    # Recombine processed segments into a single continuous trace
    processed_time_trace = combine_processed_segments(processed_segments, window_size, overlap_size, time_trace.shape[1])


    # **Compare original vs. processed signals**
    # 
    # **Note:**
    # - Interactive Plotly figure, it might take a long time to run, consider changing the plot setting/renderer or proceeding to later sections.
    # - Setting plot_segments=True will also show each individual segment.

    # In[9]:


    # plot_segments_comparison(time_trace, processed_time_trace, segments, processed_segments, window_size, overlap_size,
    #     title="Comparison of Original and Processed Segments",
    #     plot_segments=False)

    # Here SNR is defined relative to the difference between clean and noisy signals:
    #   signal_power = mean(clean^2)
    #   noise_power  = mean((noisy - clean)^2)
    #   snr_db       = 10 * log10(signal_power / noise_power)
    #
    # The plot shows:
    #   - Original vs. processed time trace, with low-SNR regions shaded
    #   - SNR vs. time curve (based on moving windows)

    snr_window_size, snr_step_size, snr_threshold = 50, 25, None
    plot_sqi_results_snr(time_trace.squeeze(), processed_time_trace.squeeze(), snr_window_size, snr_step_size, snr_threshold)
    
    # Spectrograms of the signals, this might take a long time
    # plot_spectrogram(time_trace, fs_data, title_text="Spectrogram of Original Time Trace")
    # plot_spectrogram(processed_time_trace, fs_target, title_text="Spectrogram of Processed Time Trace")

    # In[10]:

    # ## 5. Pulse segmentation and waveform averaging
    # 
    # We use the cleaned LSTM output to detect pulse boundaries (valleys), which are then used to segment both the raw and processed signals into individual beats. From these segments, we compute mean ± STD waveforms. This provides a summary of the pulse morphology and an quality check on preprocessing and normalization.
    # 
    # **Workflow:**
    # 1. Detect valleys on the processed trace (more stable than on raw data).  
    # 2. Use valley indices to segment both raw and processed signals into pulses.  
    # 3. Optionally apply z-score filtering to remove outlier beats.  
    # 4. Compute average and standard deviation waveforms; visualize with shaded error bands.
    # 
    # **Note:** If preprocessing/normalization is appropriate, the averaged raw and LSTM-processed pulses should have similar amplitudes and lie roughly in [−1, 1].
    # 

    # In[17]:


    # Find Valleys
    # - 'prominence' affects sensitivity; 'distance' ~ half (or less) a cardiac cycle at fs_target.
    _, valleys = find_peaks_and_valleys(processed_time_trace.squeeze(), prominence=0.25, distance=fs_target/2)

    # Plot Noisy and Clean Signal with Pulse Boundaries
    # Note: For the interactive plots, plotting many vertical lines can be slow for long signals.
    # plot_signals_with_boundaries(time_trace.squeeze(), processed_time_trace.squeeze(), fs_target, valleys, title="Noisy and Clean Signal with Pulse Boundaries")


    # In[18]:


    # Segment pulses from the noisy time trace
    segmented_pulses_noisy = segment_pulses(time_trace.squeeze(), valleys)

    # Segment pulses from the processed time trace
    segmented_pulses_processed = segment_pulses(processed_time_trace.squeeze(), valleys)

    # Calculate pulse mean and std (unfiltered set)
    mean_pulse_noisy, std_pulse_noisy = calculate_weighted_mean_std(segmented_pulses_noisy)
    mean_pulse_processed, std_pulse_processed = calculate_weighted_mean_std(segmented_pulses_processed)

    # Use z-score filtering to remove pulses outliers
    # Threshold=2 is a typical starting point; adjust per modality and SNR.
    filtered_pulses_noisy, weights_noisy = z_score_filter(segmented_pulses_noisy, z_threshold=2)
    filtered_pulses_processed, weights_processed = z_score_filter(segmented_pulses_processed, z_threshold=2)

    # Calculate pulse mean and std (filtered set)
    filtered_mean_pulse_noisy, filtered_std_pulse_noisy = calculate_weighted_mean_std(filtered_pulses_noisy)
    filtered_mean_pulse_processed, filtered_std_pulse_processed = calculate_weighted_mean_std(filtered_pulses_processed)


    # **Compute similarity metrics:**
    # - **Pearson correlation (r):** quantifies overall similarity in waveform shape.
    # - **Absolute difference between time-to-peak (Δ|TTP|):** captures temporal alignment of the main peak.
    # 
    # **Note:**
    # - The current implementation determines TTP by simply locating the maximum value of each pulse. For noisy signals, this can be unstable. A more robust approach would smooth the waveform before peak detection, or define TTP based on an average across several neighboring values.
    # - During final code cleanup and dataset preparation, the calculated values of r and Δ|TTP| may differ slightly from those reported in the paper due to minor implementation changes.

    # In[19]:


    # X-axis values (assuming noisy and processed pulses have the same length)
    x_noisy = np.arange(len(filtered_mean_pulse_noisy))/fs_target
    x_processed = np.arange(len(filtered_mean_pulse_processed))/fs_target

    pulse_raw = np.asarray(filtered_mean_pulse_noisy).ravel()
    pulse_lstm = np.asarray(filtered_mean_pulse_processed).ravel()
    t_pulse = np.asarray(x_noisy).ravel()

    # Pearson correlation (shape similarity, mean-centered)
    r_pearson = np.corrcoef(pulse_raw, pulse_lstm)[0, 1]

    # Time-to-peak
    ttp_raw = t_pulse[np.argmax(pulse_raw)]
    ttp_lstm = t_pulse[np.argmax(pulse_lstm)]
    delta_ttp = abs(ttp_lstm - ttp_raw)

    print(f"Pearson r = {r_pearson:.3f}")
    print(f"ΔTTP = {delta_ttp:.4f} s")


    # **Plot averaged pulse:**

    # In[20]:


    t = np.arange(0, processed_time_trace.shape[1]) / fs_target

    # Create a GridSpec with 1 row and n columns
    fig = plt.figure(figsize=(10, 3))
    gs = gridspec.GridSpec(1,3)

    # Full time trace on the entire top row (spanning both columns)
    ax_full_trace = fig.add_subplot(gs[0, 0:2])
    ax_full_trace.plot(t, time_trace.squeeze(), label='Noisy', color=color5[2], linewidth=1)
    ax_full_trace.plot(t, processed_time_trace.squeeze(), label='LSTM', color=color5[1], linewidth=1)
    ax_full_trace.vlines(x = t[valleys], ymin=-5, ymax=5, color = [0.5,0.5,0.5], linestyle='-', linewidth=0.5, label = 'Boundaries')
    ax_full_trace.set_title('Zoomed-In Signal', fontsize=7, y=1.0)
    ax_full_trace.set_xlabel('Time (s)', fontsize=7, labelpad=1)
    ax_full_trace.set_ylabel('Amplitude (a.u.)', fontsize=7, labelpad=1)
    ax_full_trace.spines['top'].set_visible(False)
    ax_full_trace.spines['right'].set_visible(False)
    ax_full_trace.tick_params(axis='both', which='major', labelsize=6)

    lgd = ax_full_trace.legend(fontsize=5,frameon=1, framealpha=0.7, ncol=3, loc=3, handlelength=0.75, handletextpad=0.3, borderaxespad=0.08, columnspacing=0.5)
    lgd.get_frame().set_linewidth(0.1)

    # define a random 10-second window
    window_length = 10  # seconds
    t_min, t_max = t.min(), t.max()
    valid_max_start = t_max - window_length
    if valid_max_start <= t_min:
        raise ValueError(f"Time axis is too short for a {window_length}-second window.")
    start_time = np.random.uniform(t_min, valid_max_start)
    end_time = start_time + window_length

    ax_full_trace.set_xlim([start_time,end_time])
    ax_full_trace.set_ylim([-1.8,1.8])

    # Averaged pulse
    ax = fig.add_subplot(gs[0, 2])

    # Add verticle lines for ttp
    ax.vlines(x = ttp_raw, ymin=-5, ymax=5, color = color5[2], linestyle='--', linewidth=0.5)
    ax.vlines(x = ttp_lstm, ymin=-5, ymax=5, color = color5[1], linestyle='--', linewidth=0.5)

    # Plot noisy mean with shaded error bars for std
    ax.plot(x_noisy, filtered_mean_pulse_noisy, color=color5[2], label='Noisy', linewidth=1)
    ax.fill_between(x_noisy, filtered_mean_pulse_noisy - filtered_std_pulse_noisy,
                    filtered_mean_pulse_noisy + filtered_std_pulse_noisy, color=color5[2], alpha=0.3)

    # Plot processed mean with shaded error bars for std
    ax.plot(x_processed, filtered_mean_pulse_processed, color=color5[1], label='LSTM', linewidth=1)
    ax.fill_between(x_processed, filtered_mean_pulse_processed - filtered_std_pulse_processed,
                    filtered_mean_pulse_processed + filtered_std_pulse_processed, color=color5[1], alpha=0.3)

    ax.text(
        0.98, 0.02,   # near bottom-right corner of the axes
        f"r = {r_pearson:.3f}\n|ΔTTP| = {delta_ttp*1000:.1f} ms",
        transform=ax.transAxes,
        ha="right", va="bottom", fontsize=5, fontweight='bold',
        multialignment="left",   # makes the lines align left *within* the box
        bbox=dict(boxstyle="round,pad=0.1", facecolor="white", alpha=0.8, linewidth=0)
    )


    # Set titles, labels, and customize the axes
    ax.set_title('Averaged Pulse', fontsize=7, y=1.0)
    ax.set_xlabel('Time (s)', fontsize=7, labelpad=1)
    # ax.set_ylabel('Normalized PPG (a.u.)', fontsize=7)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.tick_params(axis='both', which='major', labelsize=6)
    # ax.set_xticks(np.arange(0,0.9,0.2))
    ax.set_ylim(-1.8, 1.8)


    # Add labels
    # ax_full_trace.text(0, 1.24, '(a)', transform=ax_full_trace.transAxes, fontsize=7, fontweight='bold', va='top', ha='right')
    # ax.text(0, 1.24, '(b)', transform=ax.transAxes, fontsize=7, fontweight='bold', va='top', ha='right')

    # Save the figure
    # save_name = 'zoomed_in_signal_and_avg_pulse.png'
    # plt.savefig(save_name, dpi=600, bbox_inches='tight')

    plt.show()


    # Save the figure if needed
    # plt.savefig('averaged_waveform.png', dpi=600, bbox_inches='tight')

    plt.show()

        # Keep matplotlib windows open after the script finishes
    try:
        plt.ioff()
        plt.show()
    except Exception:
        pass


from utils import * # import custom helper functions
if __name__ == "__main__":
    print("Running pulsation tracing demo...")
    print("Note: the program will exit only after all open figure windows are closed. \n")

    main()